{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Attention Based Classification.ipynb","provenance":[],"authorship_tag":"ABX9TyOQessUyTAD+CCRNGzH5reP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"sqGtdkCRR0Oy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":632},"outputId":"03611b04-6ab6-4852-cccb-456d75c2022c","executionInfo":{"status":"ok","timestamp":1584981946747,"user_tz":-480,"elapsed":6780,"user":{"displayName":"qingyuan liang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTJHoGFryhWrfj2D0X8Yu7JTP_jfz9n_P4els=s64","userId":"15260138906199842493"}}},"source":["!pip install --upgrade tensorflow"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.1)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (46.0.0)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.7.2)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n","Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"McWjFyZDJeQq","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","from nltk.tokenize import TweetTokenizer\n","import datetime\n","from scipy import stats\n","from scipy.sparse import hstack, csr_matrix\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from wordcloud import WordCloud\n","from collections import Counter\n","from nltk.corpus import stopwords\n","from nltk.util import ngrams\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.multiclass import OneVsRestClassifier\n","pd.set_option('max_colwidth',400)\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Layer,Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU,  BatchNormalization\n","from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n","from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.optimizers import Adam\n","\n","from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n","from sklearn.preprocessing import OneHotEncoder\n","from tqdm import tqdm\n","import re\n","\n","import nltk\n","from sklearn.utils import shuffle\n","from tqdm import tqdm\n","#nltk.download('stopwords')\n","from sklearn import metrics"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mz3JXW7fOO-v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"cd4ecf1f-de3d-4dad-d390-2308f1880265","executionInfo":{"status":"ok","timestamp":1584982087677,"user_tz":-480,"elapsed":1693,"user":{"displayName":"qingyuan liang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTJHoGFryhWrfj2D0X8Yu7JTP_jfz9n_P4els=s64","userId":"15260138906199842493"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","path=\"/content/drive/My Drive/Colab Notebooks/NLP/05_ALBERT/\"\n","data=pd.read_csv(path+\"tweets.csv\")\n","data.head()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>target</th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>time</th>\n","      <th>username</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>1238978214090792960</td>\n","      <td>2020-03-14</td>\n","      <td>23:59:59</td>\n","      <td>ok32650586</td>\n","      <td>I hope everything turns ok! Sending love and prayers for a good outcome. ğŸ™â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>48</td>\n","      <td>4</td>\n","      <td>1237965669649412097</td>\n","      <td>2020-03-12</td>\n","      <td>04:56:30</td>\n","      <td>ok32650586</td>\n","      <td>Wow !! They are BIG dogs like you sweetie pie! â¤ï¸ğŸ¶â¤ï¸âŒâ­•ï¸âŒâ­•ï¸ğŸŒ¹</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65</td>\n","      <td>4</td>\n","      <td>1237625848347234304</td>\n","      <td>2020-03-11</td>\n","      <td>06:26:10</td>\n","      <td>ok32650586</td>\n","      <td>Thatâ€™s so wonderful!! They are angels from heaven protecting and loving us. â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>66</td>\n","      <td>4</td>\n","      <td>1237614943794413569</td>\n","      <td>2020-03-11</td>\n","      <td>05:42:51</td>\n","      <td>ok32650586</td>\n","      <td>Awwww these pictures are sooo adorable!! Kisses and hugs ğŸ¤—âŒâ­•ï¸âŒâ­•ï¸â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹ğŸŒ¹ğŸŒ¹</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>68</td>\n","      <td>4</td>\n","      <td>1237612806888800256</td>\n","      <td>2020-03-11</td>\n","      <td>05:34:21</td>\n","      <td>ok32650586</td>\n","      <td>She looks loved and happy to me! Kisses and hugs for you and yours âŒâ­•ï¸âŒâ­•ï¸â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹ğŸŒ¹ğŸŒ¹</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...                                                                               tweet\n","0           0  ...    I hope everything turns ok! Sending love and prayers for a good outcome. ğŸ™â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹\n","1          48  ...                         Wow !! They are BIG dogs like you sweetie pie! â¤ï¸ğŸ¶â¤ï¸âŒâ­•ï¸âŒâ­•ï¸ğŸŒ¹\n","2          65  ...  Thatâ€™s so wonderful!! They are angels from heaven protecting and loving us. â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹\n","3          66  ...            Awwww these pictures are sooo adorable!! Kisses and hugs ğŸ¤—âŒâ­•ï¸âŒâ­•ï¸â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹ğŸŒ¹ğŸŒ¹\n","4          68  ...   She looks loved and happy to me! Kisses and hugs for you and yours âŒâ­•ï¸âŒâ­•ï¸â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹ğŸŒ¹ğŸŒ¹\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"yIMrurJmOikI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"8509d437-e983-4ae8-f850-ddf8de36e997","executionInfo":{"status":"ok","timestamp":1584982093439,"user_tz":-480,"elapsed":2239,"user":{"displayName":"qingyuan liang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTJHoGFryhWrfj2D0X8Yu7JTP_jfz9n_P4els=s64","userId":"15260138906199842493"}}},"source":["data.drop(columns=data.columns[0],inplace=True)\n","data.loc[data['target'] ==4, 'target'] = 1\n","data.drop(columns=data.columns[1:-1],inplace=True)\n","print(data['tweet'][0])\n","data.head()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["I hope everything turns ok! Sending love and prayers for a good outcome. ğŸ™â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>I hope everything turns ok! Sending love and prayers for a good outcome. ğŸ™â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Wow !! They are BIG dogs like you sweetie pie! â¤ï¸ğŸ¶â¤ï¸âŒâ­•ï¸âŒâ­•ï¸ğŸŒ¹</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Thatâ€™s so wonderful!! They are angels from heaven protecting and loving us. â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>Awwww these pictures are sooo adorable!! Kisses and hugs ğŸ¤—âŒâ­•ï¸âŒâ­•ï¸â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹ğŸŒ¹ğŸŒ¹</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>She looks loved and happy to me! Kisses and hugs for you and yours âŒâ­•ï¸âŒâ­•ï¸â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹ğŸŒ¹ğŸŒ¹</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   target                                                                               tweet\n","0       1    I hope everything turns ok! Sending love and prayers for a good outcome. ğŸ™â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹\n","1       1                         Wow !! They are BIG dogs like you sweetie pie! â¤ï¸ğŸ¶â¤ï¸âŒâ­•ï¸âŒâ­•ï¸ğŸŒ¹\n","2       1  Thatâ€™s so wonderful!! They are angels from heaven protecting and loving us. â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹\n","3       1            Awwww these pictures are sooo adorable!! Kisses and hugs ğŸ¤—âŒâ­•ï¸âŒâ­•ï¸â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹ğŸŒ¹ğŸŒ¹\n","4       1   She looks loved and happy to me! Kisses and hugs for you and yours âŒâ­•ï¸âŒâ­•ï¸â¤ï¸ğŸ¶â¤ï¸ğŸŒ¹ğŸŒ¹ğŸŒ¹"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"UJyF1zANOsw4","colab_type":"code","colab":{}},"source":["data=data.sample(frac=1)\n","## split to train and val\n","train_df, val_df = train_test_split(data, test_size=0.2, random_state=2020)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UDUmoL2gPQCY","colab_type":"code","colab":{}},"source":["## some config values \n","embed_size = 300 # how big is each word vector\n","max_features = 95000 # how many unique words to use (i.e num rows in embedding vector)\n","maxlen = 70 # max number of words in a question to use\n","\n","## fill up the missing values\n","train_X = train_df[\"tweet\"].fillna(\"_##_\").values\n","val_X = val_df[\"tweet\"].fillna(\"_##_\").values\n","\n","## Tokenize the sentences\n","tokenizer = Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(list(train_X))\n","train_X = tokenizer.texts_to_sequences(train_X)\n","val_X = tokenizer.texts_to_sequences(val_X)\n","\n","## Pad the sentences \n","train_X = pad_sequences(train_X, maxlen=maxlen)\n","val_X = pad_sequences(val_X, maxlen=maxlen)\n","\n","## Get the target values\n","train_y = train_df['target'].values\n","val_y = val_df['target'].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNfN4uGyPjRJ","colab_type":"code","colab":{}},"source":["class Position_Embedding(Layer):\n","    \n","    def __init__(self, size=None, mode='sum', **kwargs):\n","        self.size = size\n","        self.mode = mode\n","        super(Position_Embedding, self).__init__(**kwargs)\n","        \n","    def call(self, x):\n","        if (self.size == None) or (self.mode == 'sum'):\n","            self.size = int(x.shape[-1])\n","        batch_size,seq_len = K.shape(x)[0],K.shape(x)[1]\n","        position_j = 1. / K.pow(10000., \\\n","                                 2 * K.arange(self.size / 2, dtype='float32' \\\n","                               ) / self.size)\n","        position_j = K.expand_dims(position_j, 0)\n","        position_i = K.cumsum(K.ones_like(x[:,:,0]), 1)-1 \n","        position_i = K.expand_dims(position_i, 2)\n","        position_ij = K.dot(position_i, position_j)\n","        position_ij = K.concatenate([K.cos(position_ij), K.sin(position_ij)], 2)\n","        if self.mode == 'sum':\n","            return position_ij + x\n","        elif self.mode == 'concat':\n","            return K.concatenate([position_ij, x], 2)\n","        \n","    def compute_output_shape(self, input_shape):\n","        if self.mode == 'sum':\n","            return input_shape\n","        elif self.mode == 'concat':\n","            return (input_shape[0], input_shape[1], input_shape[2]+self.size)\n","\n","\n","'''\n","output dimention: [batch_size, time_step, nb_head*size_per_head]\n","every word can be represented as a vector [nb_head*size_per_head]\n","'''\n","class Attention(Layer):\n","\n","    def __init__(self, nb_head, size_per_head, **kwargs):\n","        self.nb_head = nb_head\n","        self.size_per_head = size_per_head\n","        self.output_dim = nb_head*size_per_head\n","        super(Attention, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.WQ = self.add_weight(name='WQ', \n","                                  shape=(input_shape[0][-1], self.output_dim),\n","                                  initializer='glorot_uniform',\n","                                  trainable=True)\n","        self.WK = self.add_weight(name='WK', \n","                                  shape=(input_shape[1][-1], self.output_dim),\n","                                  initializer='glorot_uniform',\n","                                  trainable=True)\n","        self.WV = self.add_weight(name='WV', \n","                                  shape=(input_shape[2][-1], self.output_dim),\n","                                  initializer='glorot_uniform',\n","                                  trainable=True)\n","        super(Attention, self).build(input_shape)\n","        \n","    def Mask(self, inputs, seq_len, mode='mul'):\n","        if seq_len == None:\n","            return inputs\n","        else:\n","            mask = K.one_hot(seq_len[:,0], K.shape(inputs)[1])\n","            mask = 1 - K.cumsum(mask, 1)\n","            for _ in range(len(inputs.shape)-2):\n","                mask = K.expand_dims(mask, 2)\n","            if mode == 'mul':\n","                return inputs * mask\n","            if mode == 'add':\n","                return inputs - (1 - mask) * 1e12\n","                \n","    def call(self, x):\n","        if len(x) == 3:\n","            Q_seq,K_seq,V_seq = x\n","            Q_len,V_len = None,None\n","        elif len(x) == 5:\n","            Q_seq,K_seq,V_seq,Q_len,V_len = x\n","        Q_seq = K.dot(Q_seq, self.WQ)\n","        Q_seq = K.reshape(Q_seq, (-1, K.shape(Q_seq)[1], self.nb_head, self.size_per_head))\n","        Q_seq = K.permute_dimensions(Q_seq, (0,2,1,3))\n","        K_seq = K.dot(K_seq, self.WK)\n","        K_seq = K.reshape(K_seq, (-1, K.shape(K_seq)[1], self.nb_head, self.size_per_head))\n","        K_seq = K.permute_dimensions(K_seq, (0,2,1,3))\n","        V_seq = K.dot(V_seq, self.WV)\n","        V_seq = K.reshape(V_seq, (-1, K.shape(V_seq)[1], self.nb_head, self.size_per_head))\n","        V_seq = K.permute_dimensions(V_seq, (0,2,1,3))\n","        A = K.batch_dot(Q_seq, K_seq, axes=[3,3]) / self.size_per_head**0.5\n","        A = K.permute_dimensions(A, (0,3,2,1))\n","        A = self.Mask(A, V_len, 'add')\n","        A = K.permute_dimensions(A, (0,3,2,1))    \n","        A = K.softmax(A)\n","        O_seq = K.batch_dot(A, V_seq, axes=[3,2])\n","        O_seq = K.permute_dimensions(O_seq, (0,2,1,3))\n","        O_seq = K.reshape(O_seq, (-1, K.shape(O_seq)[1], self.output_dim))\n","        O_seq = self.Mask(O_seq, Q_len, 'mul')\n","        return O_seq\n","        \n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0][0], input_shape[0][1], self.output_dim)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUzBDK3RQAxs","colab_type":"code","colab":{}},"source":["config = {\n","    \"trainable\": False,\n","    \"max_len\": 70,\n","    \"max_features\": 95000,\n","    \"embed_size\": 300,\n","    \"units\": 64,\n","    \"num_heads\": 8,\n","    \"dr\": 0.5,\n","    \"epochs\": 2,\n","    \"model_checkpoint_path\": \"best_weights\",\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF9TCVC1QIsx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":719},"outputId":"df762fec-67ce-4224-cc85-276336ab2b2d","executionInfo":{"status":"error","timestamp":1584982275726,"user_tz":-480,"elapsed":2648,"user":{"displayName":"qingyuan liang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTJHoGFryhWrfj2D0X8Yu7JTP_jfz9n_P4els=s64","userId":"15260138906199842493"}}},"source":["def build_model(config):\n","    inp = Input(shape = (config[\"max_len\"],))\n","    \n","    x = Embedding(config[\"max_features\"], config[\"embed_size\"], trainable = config[\"trainable\"])(inp)\n","    x = Position_Embedding()(x)\n","    x = Attention(config[\"num_heads\"], config[\"units\"])([x, x, x])  #output: [batch_size, time_step, nb_head*size_per_head]\n","    x = GlobalAveragePooling1D()(x)\n","    x = Dropout(config[\"dr\"])(x)\n","    \n","    x = Dense(1, activation='sigmoid')(x)\n","    \n","    model = Model(inputs = inp, outputs = x)\n","    model.compile(\n","        loss = \"binary_crossentropy\", \n","        #optimizer = Adam(lr = config[\"lr\"], decay = config[\"lr_d\"]), \n","        optimizer = \"nadam\",\n","        metrics = [\"accuracy\"])\n","    \n","    return model\n","\n","model = build_model(config)\n","model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"],"execution_count":14,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-9940c945d732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-9940c945d732>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embed_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trainable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPosition_Embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_heads\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"units\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#output: [batch_size, time_step, nb_head*size_per_head]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    772\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-11-16434a638645>:86 call  *\n        A = K.permute_dimensions(A, (0,3,2,1))\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:2744 permute_dimensions\n        return array_ops.transpose(x, perm=pattern)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1946 transpose\n        return transpose_fn(a, perm, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py:10537 transpose\n        \"Transpose\", x=x, perm=perm, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension must be 5 but is 4 for 'attention/transpose_7' (op: 'Transpose') with input shapes: [?,8,?,8,?], [4].\n"]}]}]}